# plan
[ ] explore and understand the CLIP interaction notebook. 
- Know how to take an image and encode then compare it to text
[ ] load images into vector db
[ ] explore the space of duplicate image search
[ ] explore similar image search
[ ] explore search of images based on text
[ ] 



# Scenarios we need to test
- I like this image, find me others like it
- recommender engine for similar items that I've looked at recently
- semantic search instead of keyword search based on predefined tags
- semantic search of images
- reverse image search
- define likes and we recommend similar items for you





# Analysis
- It seems using OpenAI clip on MNIST is shit



# Interesting Links

https://colab.research.google.com/github/robgon-art/open-clip/blob/main/Create_Captions_with_OpenCLIP.ipynb
